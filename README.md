
# Dockerとは？

## 何をするものなの？何ができるの？

アプリケーションの実行に必要なソフトウェアとその依存ファイル郡（ディレクトリ構造を含む）をパッケージングして、ポータブルに、手軽に簡単に利用できるようにするものです。
例えばPHPであれば、「バージョン8.0でimagemagickが使えるphp本体とその依存ライブラリ一式」をパッケージ化しておくと、
Dockerがインストールされているマシンであればそれをダウンロードするだけでとても簡単にコマンド一つで動作させることができます。

アプリを動作させるための依存ファイルをパッケージにしたもの

ライブラリやばいなりといった、ディレクトリ構造とファイル一式をポータブルにして、それを物理マシンやホストのディレクトリといったリソースにアタッチするイメージ

## 何で必要なの？何がすごいの？何が嬉しいの？

- 一言でいうと仮想化技術を使ってパワーアップしたchroot

通常Linuxであればソフトウェアの動作には本体の実行可能なバイナリファイルだけではなく、それに付随する共有ライブラリもあらかじめPCにインストールされている必要があります。
あるソフトウェアを使うために共有ライブラリをアップデートすると、その共有ライブラリを使用している他のソフトウェアが動かなくなったり、環境が壊れやすいです。
そのため同じ共有ライブラリ、同じソフトウェアの複数のバージョンを同時に動作させたい場面が出てきます。
chrootのようなものを思い浮かべてください。
特定のディレクトリをルートに見立てて、共有ライブラリや実行可能バイナリのディレクトリを複数作り、それを切り替えることで互いに独立した環境を構築することができます。
Dockerは仮想化の技術を使ってそれをさらに押し進めたものと考えて良いでしょう。独立性を高める、セキュリティを高める

ファイルを削除してしまったり

ホストの環境を汚さない
堅牢、構造的に独立性が高い

セキュリティ的に良い、完全に切り離されている、外のプロセスが見えないし
非破壊で、壊れにくい

環境に合わせてアプリが動く、本番環境と開発環境が違う、動かないトラブル

さくらの共用レンタルサーバーのようなものを思い浮かべても良いかもしれない
頑張れば、パスを変えたりして、自分でビルドしたアプリが使えたりする
バージョンの違うライブラリを用意して、パスを切り替えて複数のアプリ実行環境を用意する
違うユーザーでログインして、ちょっと違う環境で、アプリを実行するだけ

- 参考
    - [chrootとは 監獄? 最も基本的な仮想化？](https://log.dot-co.co.jp/chroot/)

## Dockerの肝。ファイルシステム仮想化

- ファイルシステムをレイヤーに見立てて、重ねて合わせて（上書きマウント）使用することができる
- overlayfsとは
    - https://qiita.com/ryuichi1208/items/0bd0284dcf8a09299504#overlayfs%E3%81%A8%E3%81%AF

- 同じパスのディレクトリに格納されているファイルがプロセス（仮想マシン）毎に異なる
- ライブラリをインストールするディレクトリやPATHなどの環境変数は通常通りでよい

```
/bin
/lib
~/.bashrc
```

同じパス名にファイルシステムをオーバーロードする

実行時にパッケージをレイヤードファイルシステムに展開する
プロセスから見た場合に特定の場所には自分が必要としているファイルが配置されている
自分が必要としているバージョンのライブラリだったり
他のプロセスとは共有してない設定ファイルだったりがある

## 他の仮想化技術との比較

- 完全仮想化、準仮想化
    - VirtualBox,HyperV,KVM
    - ハードウェアをエミュレーション、または独自ドライバを提供
    - OSレベルで仮想化を提供する、ホストOSと違うOSのアプリも動かせる、大体のアプリが動く
    - 特徴
        - 動作が重たい
            - 起動が遅い、普通のPCの電源をつけてから立ち上がるまでと同じ
            - ハードウェアをエミュレートするのでその分パフォーマンスが落ちる
            - ストレージ消費が大きい

- コンテナ型仮想化
    - Dockerなど
    - ハードウェアをエミュレートしない
    - ホストOSのカーネルを共有する、ホストOSで動くアプリしか動作しない
        - ディストリビューションとバージョンはホストOSと別のものを動作させられる
    - 動作が軽い
        - 起動が早い、1秒もかからない
        - ハードウェアをエミューレートせずにホストOS上でそのまま動作するのでパフォーマンスが落ちない
        - ストレージ消費が少ない
    - GUIで操作できない

## 他の仮想化技術との違い

### 仮想マシンのライフサイクルが全然違う

Webアプリ(Laravel等)を動かすことを考える

- VirtualBox
    - 基本的に常時電源ON
    - 一つの仮想マシンに複数のアプリケーション
        - チーム内で違うバージョンのPHPで開発してしまう可能性

- Docker
    - 基本は電源OFF、必要なタイミングで必要な時だけ、使わなくなったらすぐに破棄
    - 一つのアプリケーションに一つの仮想マシン
        - アプリケーション毎に本番環境と全く同じバージョンで開発

- 一つのプロセス（コマンド）を実行するために一つの仮想マシンが動作する
    - プロセスの数だけ仮想マシンが必要なので、基本1台だけのVirtalBoxと比べると全然起動するマシンの数が違う
    - Dockerは仮想マシンの起動に1秒もかからないくらい軽いため、仮想マシンを意識せずに、ただコマンドを実行しているのと見分けがつかない
    - そのため例えば compose install を実行するためだけに仮想マシンがあったりする

```bash
% docker run --rm php:7.1.6-apache php -v
# 例えば上記のようにPHPのバージョンを表示するだけのコマンドを仮想マシンで実行すると
PHP 7.1.6 (cli) (built: Jul  3 2017 22:30:08) ( NTS )
Copyright (c) 1997-2017 The PHP Group
Zend Engine v3.1.0, Copyright (c) 1998-2017 Zend Technologies
# 仮想マシンが一瞬で立ち上がって php -v コマンドが実行されて結果が標準出力で返される
# プロセスが終了すると仮想マシンも一瞬でシャットダウンする
```

### アプリケーションのデプロイの考え方が全然違う

- Dockerはアプリケーションを中心に考える、仮想マシンありきではない
- アプリケーション毎にカスタマイズされた専用の動作環境を用意する
- 仮想マシンにアプリケーションを配置して動作させるのとは反対の考え方

### GUIがない

- VirtualBoxの場合はグラフィカルなコンソール上から仮想マシンを操作できる
- Dockerは仮想マシンの起動など操作は基本コマンドで行う
    - 動作中の仮想マシンに至っては操作する必要性がほぼない。ターミナルから仮想マシンに接続して操作することは一応きる

## Dockerの構成要素

### イメージとは?
- イメージとはVirtualBoxでいうところのスナップショット
- ディレクトリ構造やファイルがひとまとまりになっている
- イメージはレジストリサーバにアップロードして共有できる
- VirtualBoxなどのイメージと比較すると小さいファイルサイズで扱いやすい

#### Docker Hub
- Docker HubはDocker社が提供するレジストリ
- nodeでいうnpmのようなもの
- PHPやMySQLなど多くのソフトウェアが公式イメージを提供している

### コンテナとは？
- VirtualBoxでいうところの仮想マシンをスナップショットから起動して電源がONの状態
- 起動時に実行するコマンドを指定する
- 基本的には一つのプロセスのみが起動している
- プロセスが終了すると仮想マシンの電源もoffになる
    - ファイルに対する変更などはメモリ上にあるため停止すると変更の情報は失われる
        - PHPアプリでローカルディレクトリに写真をアップロードするような設計だと再起動で消えてしまう。。

### build
- VirtualBoxの場合は仮想マシンを立ち上げてターミナルから必要なソフトウェアやライブラリをインストールする作業にあたる
- Dockerの場合はDockerfileからイメージを作ることを言う
- Dockerfileは　`apt-get install zlib` などのようにターミナルを操作するのと同じように記述して、必要なソフトウェアやライブラリを定義する
- Dockerfileは単なるテキストファイルなのでバージョン管理できる。配布や共有も容易。PHPアプリなどのプロジェクトディレクトリに置いておける。
- VirtualBoxなどで手動でインストールするのに比べると、やり直しが容易でトライアンドエラーで進めやすい。

### network
- コンテナ間の通信は基本的にはネットワークを経由で行う
    - phpからnodeをshell経由で呼び出したりというのは実は苦手。。
- コンテナのポートはホストPCに転送することで外部に公開することもできる

```bash
docker run --rm -ti -p 8080:80 php:8.0.19-apache
# -p 8080:80 というオプションでコンテナの80ポートをホストPCの8080ポートに転送している
```

### volume
- ホストのファイルやディレクトリなどをマウントしてコンテナ内から読み書きできる
- 複数のコンテナで同じディレクトリをマウントすることもできるためファイルを使ってコンテナ間通信もできる

```bash
docker run --rm -ti -v "/home/myuser/data:/var/www/html" php:8.0.19-apache bash -i
# コンテナの/var/www/htmlディレクトリにホストの/home/myuser/dataをマウント
```

## docker-compose

コンテナの起動オプションをyamlファイルにかける
設定ファイルとして使える、テキストなのでバージョン管理や共有もできる
ポートフォワードの設定、ボリューム、実行コマンド
WebサーバとDBサーバというようにスタックを書いたり、それぞれの依存関係も書ける
開発では基本これしか使わない

Docker Desktop をインストールするとついてくる

- スタック内の他のマシンにマシン名でネットワークアクセスすることができる

```yaml
- php
  - port
    - "8080:80"
  - volume
    - "./:/var/www/html"
```